{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "unavailable_papers = []\n",
    "duplicates = []\n",
    "papers_directory = \"papers/Robotic planning - Evolutionary robotics\"\n",
    "#initial csv\n",
    "initial_csv_file = \"papers/Robotic planning - Evolutionary robotics.csv\"\n",
    "#csv directory - after removing unavailable papers\n",
    "csv_file_after_removed_unavailable_papers = \"temp.csv\"\n",
    "#csv directory - after removing duplicates\n",
    "final_output_csv = \"Robotic planning - Evolutionary robotics_final.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def check_unavailable_papers(initial_csv_file, papers_directory):\n",
    "    \n",
    "\n",
    "    # Check if the papers directory exists\n",
    "    if not os.path.exists(papers_directory):\n",
    "        print(f\"The directory '{papers_directory}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Read the CSV file with the appropriate encoding\n",
    "    with open(initial_csv_file, 'r', encoding='utf-8-sig',errors='replace') as file:\n",
    "        reader = csv.reader(file)\n",
    "        # next(reader)  # Skip the header row if it exists\n",
    "        for col in reader:\n",
    "            file_name = col[3]  # Assuming the fourth column contains file names\n",
    "            file_path = os.path.join(papers_directory, file_name)\n",
    "            if not file_path.endswith(\".pdf\"):\n",
    "                file_path += \".pdf\"\n",
    "            if \":\" in file_path:\n",
    "                file_path = file_path.replace(\":\", \"_\")\n",
    "            if not os.path.exists(file_path):\n",
    "                unavailable_papers.append(file_name)\n",
    "\n",
    "    if unavailable_papers:\n",
    "        print(\"Unavailable papers:\")\n",
    "        for paper in unavailable_papers:\n",
    "            print(paper)\n",
    "    else:\n",
    "        print(\"All papers are available.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_unavailable_papers(initial_csv_file, csv_file_after_removed_unavailable_papers):\n",
    "\n",
    "    if not unavailable_papers:\n",
    "        print(\"No unavailable papers to remove.\")\n",
    "        return\n",
    "\n",
    "    # Read the original CSV file and write a new one excluding unavailable papers\n",
    "    with open(initial_csv_file, 'r', encoding='utf-8-sig',errors='replace') as infile, open(csv_file_after_removed_unavailable_papers, 'w', newline='', encoding='utf-8-sig',errors='replace') as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "\n",
    "        for row in reader:\n",
    "            file_name = row[3]  # Assuming the fourth column contains file names\n",
    "            if file_name not in unavailable_papers:\n",
    "                writer.writerow(row)\n",
    "\n",
    "    print(f\"Unavailable papers removed. Updated CSV saved as '{csv_file_after_removed_unavailable_papers}'.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def find_duplicate_records(csv_file):\n",
    "    records = defaultdict(int)\n",
    "\n",
    "    # Read the CSV file with the appropriate encoding\n",
    "    with open(csv_file, 'r', encoding='utf-8-sig',errors='replace') as file:\n",
    "        reader = csv.reader(file)\n",
    "        # header = next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            record = tuple(row)  # Convert the row to a tuple to make it hashable\n",
    "            records[record] += 1\n",
    "            if records[record] == 2:  # Only add to duplicates list the first time a duplicate is found\n",
    "                duplicates.append(record)\n",
    "\n",
    "    if duplicates:\n",
    "        print(\"Duplicate records found:\")\n",
    "        for duplicate in duplicates:\n",
    "            print(duplicate)\n",
    "    else:\n",
    "        print(\"No duplicate records found.\")\n",
    "    return duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_records(csv_file_after_removed_duplicates, final_output_csv):\n",
    "    records = set()\n",
    "    duplicates_removed = 0\n",
    "\n",
    "    # Read the original CSV file and write a new one excluding duplicate records\n",
    "    with open(csv_file_after_removed_duplicates, 'r', encoding='utf-8-sig',errors='replace') as infile, open(final_output_csv, 'w', newline='', encoding='utf-8-sig',errors='replace') as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "\n",
    "        for row in reader:\n",
    "            record = tuple(row)  # Convert the row to a tuple to make it hashable\n",
    "            if record not in records:\n",
    "                writer.writerow(row)\n",
    "                records.add(record)\n",
    "            else:\n",
    "                duplicates_removed += 1\n",
    "\n",
    "    print(f\"Duplicate records removed: {duplicates_removed}. Updated CSV saved as '{final_output_csv}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All papers are available.\n"
     ]
    }
   ],
   "source": [
    "#check unavilable papers\n",
    "check_unavailable_papers(initial_csv_file, papers_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No unavailable papers to remove.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "remove_unavailable_papers(initial_csv_file, csv_file_after_removed_unavailable_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate records found.\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate records\n",
    "if os.path.exists(csv_file_after_removed_unavailable_papers):\n",
    "  find_duplicate_records(csv_file_after_removed_unavailable_papers)\n",
    "else:\n",
    "  find_duplicate_records(initial_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate records removed: 0. Updated CSV saved as 'Robotic planning - Evolutionary robotics_final.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate records\n",
    "if os.path.exists(csv_file_after_removed_unavailable_papers):\n",
    "    remove_duplicate_records(csv_file_after_removed_unavailable_papers, final_output_csv)\n",
    "else:\n",
    "    remove_duplicate_records(initial_csv_file,final_output_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
